{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 라이브러리(프로그래밍 도구) 설치 및 설정\n",
        "\n",
        "* 필요한 프로그래밍 라이브러리 도구를 설치하고 설정하는 과정입니다.\n",
        "* 만약 이 코드를 다시 쓸 일이 있다면 반드시 이 부분을 실행해주어야 합니다!!!"
      ],
      "metadata": {
        "id": "3LRdjpEhdxEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fastai2 라이브러리 설치\n",
        "!pip install fastai2\n",
        "\n",
        "#한글 폰트 처리를 위한 라이브러리 설치\n",
        "!pip install koreanize-matplotlib\n",
        "\n",
        "#fastbook 라이브러리 설치 및 불러오기\n",
        "#실행이 안되면 다시 실행할 것~\n",
        "\n",
        "!pip install -Uqq fastbook"
      ],
      "metadata": {
        "id": "TwGTaD-zMj3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f6HW-d1zU8Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CSV 파일 업로드 후 독립변수, 종속변수 설정\n",
        "\n",
        "* 계속 강조하지만 AI 학습을 위해서는 데이터가 필요하며\n",
        "* CSV는 테이블(표) 형태의 데이터로 AI 학습에 널리 사용됩니다.\n",
        "* 첫줄은 데이터 속성(데이터의 이름)이 오고 두번째 줄부터 데이터가 누적됩니다.\n",
        "* AI 학습이란 그 데이터 중 알고 싶은 내용(종속변수)를 알고 싶은 내용에 관련 있는 요소(독립변수)를 설정한 후 독립변수가 종속변수에 얼마나 영향을 주는지를 데이터를 통해 찾아내는 과정입니다.\n",
        "* CSV를 업로드 한 후 독립변수, 종속변수 설정 후 왼쪽부터 버튼 2개를 누르고 작업해줘야 합니다!\n",
        "* 여러분들이 설정한 결과는 CONFIG에 저장됩니다!!"
      ],
      "metadata": {
        "id": "VXDvNUWPd7Py"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDE_0yyjMSye"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from google.colab import files\n",
        "import os\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "# 파일 업로드 버튼\n",
        "upload_button = widgets.Button(description=\"CSV 파일 업로드\", button_style='success')\n",
        "output = widgets.Output()\n",
        "\n",
        "# 업로드된 파일 이름과 데이터프레임 저장용 전역 변수\n",
        "uploaded_file_name = None\n",
        "df = None  # 전역 데이터프레임\n",
        "\n",
        "# 경로 설정\n",
        "path = \"/content/drive/MyDrive/AI기초 서비스 수행(수치 회귀)\"\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "    print(f\"경로가 존재하지 않아 새로 생성했습니다: {path}\")\n",
        "else:\n",
        "    print(f\"파일이 저장될 경로: {path}\")\n",
        "\n",
        "# 버튼 및 상태 메시지: 전역 생성\n",
        "variable_button = widgets.Button(description=\"변수 설정 완료\", button_style='primary')\n",
        "save_button = widgets.Button(description=\"설정 저장\", button_style='success')\n",
        "save_status = widgets.Label(value=\"\")  # 저장 완료 메시지\n",
        "\n",
        "# 속성 설정 UI 생성 함수\n",
        "def create_attribute_settings(df):\n",
        "    settings = []\n",
        "    for col in df.columns:\n",
        "        # 역할 선택 (독립변수, 종속변수, 무시)\n",
        "        role_dropdown = widgets.Dropdown(\n",
        "            options=['독립변수', '종속변수', '무시'],\n",
        "            value='무시',\n",
        "            description=f'{col}:',\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "\n",
        "        # 데이터 유형 선택 (숫자형, 범주형)\n",
        "        dtype_dropdown = widgets.Dropdown(\n",
        "            options=['숫자형', '범주형'],\n",
        "            value='숫자형',\n",
        "            description='데이터 유형:',\n",
        "            style={'description_width': 'initial'},\n",
        "            disabled=True  # 기본적으로 비활성화\n",
        "        )\n",
        "\n",
        "        # 역할 변경 시 데이터 유형 활성화/비활성화\n",
        "        def toggle_dtype(change):\n",
        "            dtype_dropdown.disabled = (change['new'] == '무시')\n",
        "\n",
        "        role_dropdown.observe(toggle_dtype, names='value')\n",
        "\n",
        "        # 위젯 묶기\n",
        "        row = widgets.HBox([role_dropdown, dtype_dropdown])\n",
        "        settings.append((col, role_dropdown, dtype_dropdown, row))\n",
        "    return settings\n",
        "\n",
        "# 버튼 동작 정의\n",
        "def update_dtype_locks(_):\n",
        "    global settings\n",
        "    for _, role, dtype, _ in settings:\n",
        "        dtype.disabled = (role.value == '무시')\n",
        "    with output:\n",
        "        print(\"변수 설정 완료! 데이터 유형을 수정할 수 있습니다.\")\n",
        "\n",
        "def save_config(_):\n",
        "    global CONFIG\n",
        "    independent_vars = []\n",
        "    dependent_var = None\n",
        "    ignored_vars = []\n",
        "    data_types = {}\n",
        "\n",
        "    for col, role, dtype, _ in settings:\n",
        "        if role.value == '독립변수':\n",
        "            independent_vars.append(col)\n",
        "            data_types[col] = dtype.value\n",
        "        elif role.value == '종속변수':\n",
        "            dependent_var = col\n",
        "            data_types[col] = dtype.value\n",
        "        else:\n",
        "            ignored_vars.append(col)\n",
        "\n",
        "    CONFIG = {\n",
        "        \"종속변수\": dependent_var,\n",
        "        \"독립변수\": independent_vars,\n",
        "        \"무시할 변수\": ignored_vars,\n",
        "        \"데이터 유형\": data_types\n",
        "    }\n",
        "\n",
        "    save_status.value = \"설정이 저장되었습니다!\"\n",
        "    with output:\n",
        "        print(\"설정이 저장되었습니다!\")\n",
        "        print(CONFIG)\n",
        "\n",
        "# 버튼 이벤트 연결 (초기 연결)\n",
        "variable_button.on_click(update_dtype_locks)\n",
        "save_button.on_click(save_config)\n",
        "\n",
        "# 파일 업로드 및 처리 함수\n",
        "def upload_and_process_file(_):\n",
        "    global uploaded_file_name, df, settings\n",
        "    output.clear_output()\n",
        "\n",
        "    # 파일 업로드\n",
        "    with output:\n",
        "        print(\"CSV 파일을 업로드하세요.\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        with output:\n",
        "            print(\"파일 업로드에 실패했습니다. 다시 시도해주세요.\")\n",
        "        return\n",
        "\n",
        "    # 파일 저장 및 데이터프레임 생성\n",
        "    for file_name in uploaded.keys():\n",
        "        uploaded_file_name = file_name\n",
        "        file_path = os.path.join(path, file_name)  # 파일 저장 경로\n",
        "        with open(file_path, \"wb\") as f:\n",
        "            f.write(uploaded[file_name])  # 파일 저장\n",
        "        print(f\"업로드된 파일이 저장되었습니다: {file_path}\")\n",
        "\n",
        "    # 파일 읽기\n",
        "    try:\n",
        "        df = pd.read_csv(file_path, encoding='utf-8')\n",
        "    except Exception:\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
        "        except Exception:\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, encoding='cp949')\n",
        "            except Exception:\n",
        "                with output:\n",
        "                    print(\"파일을 열 수 없습니다. 파일 인코딩을 확인해주세요.\")\n",
        "                return\n",
        "\n",
        "    # 데이터 정보 출력\n",
        "    with output:\n",
        "        print(\"\\n데이터 정보:\")\n",
        "        display(df.info())\n",
        "        print(\"\\n데이터 미리보기:\")\n",
        "        display(df.head())\n",
        "        print(\"\\n데이터 분포:\")\n",
        "        display(df.describe())\n",
        "        print(\"\\n데이터 상관도\")\n",
        "        num_df = df.select_dtypes(include='number')\n",
        "\n",
        "        correlation_matrix = num_df.corr()\n",
        "\n",
        "        # Plotly를 사용한 상관도 시각화\n",
        "        fig = px.imshow(correlation_matrix,\n",
        "                        text_auto=True,\n",
        "                        color_continuous_scale='Viridis',\n",
        "                        title='업로드 데이터 상관행렬 ')\n",
        "\n",
        "        fig.write_html(\"상관도.html\")\n",
        "\n",
        "    # 속성 설정 UI 생성\n",
        "    settings = create_attribute_settings(df)\n",
        "    settings_ui = widgets.VBox([s[3] for s in settings])\n",
        "\n",
        "    # UI 출력\n",
        "    display(settings_ui)  # 속성 설정 드롭다운 출력\n",
        "    display(widgets.HBox([variable_button, save_button]))  # 버튼 출력\n",
        "    display(save_status)  # 저장 상태 메시지 출력\n",
        "\n",
        "# 파일 업로드 버튼 클릭 이벤트 연결\n",
        "upload_button.on_click(upload_and_process_file)\n",
        "\n",
        "# UI 표시\n",
        "display(widgets.VBox([upload_button, output]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(CONFIG)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJYZI5jvNoqd",
        "outputId": "c67c9a0c-217b-47b7-fc5d-4efc93cee7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'종속변수': '거래금액(만원)', '독립변수': ['단지명', '전용면적(㎡)', '계약연도', '계약월', '층', '건축년도'], '무시할 변수': ['NO', '주소1', '주소2', '평수(전용)', '계약년월', '계약일', '동', '도로명'], '데이터 유형': {'단지명': '범주형', '전용면적(㎡)': '숫자형', '계약연도': '숫자형', '계약월': '숫자형', '거래금액(만원)': '숫자형', '층': '숫자형', '건축년도': '숫자형'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. fastai 신경망 회귀 모델\n",
        "\n",
        "* 신경망(딥러닝)은 일반적으로 머신러닝보다 성능이 좋다고 알려져있지만\n",
        "* 모든 경우에 신경망 모델이 효과적인것은 아닙니다.\n",
        "* 여기서는 신경망을 통해 회귀모델을 만들어보고 성능을 확인해보겠습니다.\n",
        "* 이후 만든 모델을 통해 값을 예측해보겠습니다!"
      ],
      "metadata": {
        "id": "5at3GJoFeTTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fastai.tabular.all import *\n",
        "import pickle\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1. 무시할 변수 제거\n",
        "df = df.drop(CONFIG['무시할 변수'], axis=1, errors='ignore')\n",
        "\n",
        "# 2. 종속변수 및 독립변수 설정\n",
        "y_col = CONFIG['종속변수']\n",
        "x_cols = CONFIG['독립변수']\n",
        "\n",
        "# 3. 데이터 정규화 및 범주형 변수 처리 (fastai가 지원)\n",
        "cat_names = [col for col, dtype in CONFIG['데이터 유형'].items() if dtype == '범주형']\n",
        "cont_names = [col for col, dtype in CONFIG['데이터 유형'].items() if dtype == '숫자형' and col != y_col]\n",
        "\n",
        "# fastai 데이터로더 생성\n",
        "dls = TabularDataLoaders.from_df(\n",
        "    df, y_names=y_col, cat_names=cat_names, cont_names=cont_names, procs=[Categorify, Normalize]\n",
        ")\n",
        "\n",
        "# 4. 모델 생성 및 학습 (인공신경망 딥러닝 기반!)\n",
        "learn = tabular_learner(dls, metrics=rmse)\n",
        "learn.fit_one_cycle(5)  # 5 에포크 학습\n",
        "\n",
        "# 5. Normalize 및 Categorify 정보 추출\n",
        "normalize_procs = [proc for proc in dls.train.procs if isinstance(proc, Normalize)][0]\n",
        "means = {name: normalize_procs.means[name] for name in cont_names}\n",
        "stds = {name: normalize_procs.stds[name] for name in cont_names}\n",
        "\n",
        "\n",
        "# 6. 정규화 여부 포함\n",
        "def get_normalization_info(name):\n",
        "    return {\n",
        "        \"is_normalized\": name in means,\n",
        "        \"mean\": means.get(name, None),\n",
        "        \"std\": stds.get(name, None)\n",
        "    }\n",
        "\n",
        "normalization_info = {name: get_normalization_info(name) for name in cont_names}\n",
        "\n",
        "categorify_maps = {\n",
        "    cat: dls.classes[cat] for cat in cat_names if cat in dls.classes\n",
        "}\n",
        "\n",
        "\n",
        "# 7. 메타 데이터 저장\n",
        "meta_data = {\n",
        "    \"model\": learn,  # fastai 모델을 직렬화\n",
        "    \"cat_names\": cat_names,\n",
        "    \"cont_names\": cont_names,\n",
        "    \"categorify_maps\": categorify_maps,  # 범주형 변수 인코딩 정보\n",
        "    \"normalize\": normalization_info,  # 정규화 정보 포함\n",
        "    \"y_names\": [y_col],\n",
        "    \"procs\": [\"Categorify\", \"Normalize\"]  # 전처리 정보\n",
        "}\n",
        "\n",
        "# 8. 모델 및 CONFIG 저장\n",
        "\n",
        "model_path = path+\"/regression_model(fastai).pkl\"\n",
        "#learn.export(model_path)  # fastai 모델 저장\n",
        "with open(model_path, \"wb\") as f:\n",
        "    pickle.dump(meta_data, f)\n",
        "\n",
        "print(f\"딥러닝 기반 회귀 모델이 {model_path}에 저장되었습니다.\")\n",
        "\n",
        "# 9. 검증 데이터셋에 대한 예측값과 실제값 가져오기\n",
        "preds, targets = learn.get_preds()\n",
        "r2 = r2_score(targets.numpy(), preds.numpy())\n",
        "print(f\"모델의 R^2 Score는 {r2}입니다. 만약 r2값이 0.5미만이라면 데이터를 보강(더 많은 데이터)하거나 독립변수 종속변수를 다시 설정해보세요!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "eNKglpS5WEaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 값 예측해보기\n",
        "\n",
        "* 만들어진 신경망 회귀 모델을 통해 값을 예측해보는 코드입니다.\n",
        "* 모델이 잘 돌아가는지를 테스트 하기 위해 필요합니다."
      ],
      "metadata": {
        "id": "-X0KS31XeeUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 10. 사용자 입력 인터페이스 생성\n",
        "cat_inputs = {}\n",
        "cont_inputs = {}\n",
        "\n",
        "print(\"### 사용자 입력 인터페이스 생성 중...\")\n",
        "\n",
        "# 범주형 입력 위젯 생성\n",
        "for cat in cat_names:\n",
        "    if cat in df.columns:\n",
        "        options = df[cat].unique()\n",
        "        cat_inputs[cat] = widgets.Dropdown(\n",
        "            options=options,\n",
        "            description=f\"{cat}:\",\n",
        "            style={\"description_width\": \"initial\"}\n",
        "        )\n",
        "        display(cat_inputs[cat])\n",
        "\n",
        "# 연속형 입력 위젯 생성\n",
        "for cont in cont_names:\n",
        "    cont_inputs[cont] = widgets.FloatText(\n",
        "        description=f\"{cont}:\",\n",
        "        style={\"description_width\": \"initial\"}\n",
        "    )\n",
        "    display(cont_inputs[cont])\n",
        "\n",
        "# 예측 버튼 생성\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def predict_callback(_):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        try:\n",
        "            # 입력 데이터 준비\n",
        "            input_data = []\n",
        "\n",
        "            # 범주형 데이터 인코딩\n",
        "            for cat in cat_names:\n",
        "                if cat in cat_inputs:\n",
        "                    category = cat_inputs[cat].value\n",
        "                    encoded_value = categorify_maps[cat].o2i[category]  # 인코딩된 값 가져오기\n",
        "                    input_data.append(encoded_value)\n",
        "\n",
        "            # 연속형 데이터 정규화\n",
        "            for cont in cont_names:\n",
        "                if cont in cont_inputs:\n",
        "                    raw_value = cont_inputs[cont].value\n",
        "                    mean = normalization_info[cont][\"mean\"]\n",
        "                    std = normalization_info[cont][\"std\"]\n",
        "                    normalized_value = (raw_value - mean) / std  # 정규화 수행\n",
        "                    input_data.append(normalized_value)\n",
        "\n",
        "            # 입력 데이터를 DataLoader로 변환\n",
        "            test_dl = dls.test_dl(pd.DataFrame([input_data], columns=cat_names + cont_names))\n",
        "\n",
        "            # 예측 수행\n",
        "            prediction = learn.get_preds(dl=test_dl)[0][0].item()\n",
        "            print(f\"예측값: {prediction}\")\n",
        "        except Exception as e:\n",
        "            print(f\"에러 발생: {e}\")\n",
        "\n",
        "\n",
        "predict_button.on_click(predict_callback)\n",
        "display(predict_button, output)\n"
      ],
      "metadata": {
        "id": "TgAcayKi9_az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 랜덤포레스트 머신러닝 모델\n",
        "\n",
        "* 랜덤포레스트 모델은 타이타닉 데이터에 설명했던 것처럼\n",
        "* 여러 트리 알고리즘을 조합해 사용하는 모델입니다.\n",
        "* 파이썬 sklearn(싸이킷런) 라이브러리를 활용해 모델을 만들고\n",
        "* 이후 만든 모델을 통해 값을 예측해보겠습니다!"
      ],
      "metadata": {
        "id": "B-jYcCNOek7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fastai.tabular.all import *\n",
        "import pickle\n",
        "from sklearn.metrics import r2_score\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 가져오기\n",
        "train_x, train_y = dls.train.xs, dls.train.ys\n",
        "valid_x, valid_y = dls.valid.xs, dls.valid.ys\n",
        "\n",
        "\n",
        "# Scikit-learn 회귀 모델 (Random Forest)\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(train_x, train_y.values.ravel())  # 학습\n",
        "\n",
        "# 검증 데이터 평가\n",
        "preds = rf_model.predict(valid_x)\n",
        "rmse = np.sqrt(mean_squared_error(valid_y, preds))\n",
        "r2 = r2_score(valid_y, preds)\n",
        "print(f\"Random Forest RMSE: {rmse}\")\n",
        "print(f\"Random Forest R2: {r2}\")\n",
        "\n",
        "# Normalize 및 Categorify 정보 추출\n",
        "normalize_procs = [proc for proc in dls.train.procs if isinstance(proc, Normalize)][0]\n",
        "means = {name: normalize_procs.means[name] for name in cont_names}\n",
        "stds = {name: normalize_procs.stds[name] for name in cont_names}\n",
        "\n",
        "\n",
        "#메타 데이터 형식 저장(모델 속성 정보)\n",
        "meta_data = {\n",
        "    \"model\": rf_model,\n",
        "    \"cat_names\": [col for col in CONFIG['독립변수'] if CONFIG['데이터 유형'][col] == \"범주형\"],  # 범주형 독립변수\n",
        "    \"cont_names\": [col for col in CONFIG['독립변수'] if CONFIG['데이터 유형'][col] == \"숫자형\"],  # 숫자형 독립변수\n",
        "    \"y_names\": CONFIG[\"종속변수\"],  # 종속변수\n",
        "    \"procs\": [\"Categorify\", \"Normalize\"],  # 전처리 정보 (필요 시 수정)\n",
        "}\n",
        "\n",
        "# 정규화 여부 포함\n",
        "def get_normalization_info(name):\n",
        "    return {\n",
        "        \"is_normalized\": name in means,\n",
        "        \"mean\": means.get(name, None),\n",
        "        \"std\": stds.get(name, None)\n",
        "    }\n",
        "\n",
        "normalization_info = {name: get_normalization_info(name) for name in cont_names}\n",
        "\n",
        "# 범주형 변수 매핑 정보 추출\n",
        "categorify_maps = {\n",
        "    cat: dls.classes[cat] for cat in cat_names if cat in dls.classes\n",
        "}\n",
        "\n",
        "# Random Forest 모델 저장\n",
        "meta_data = {\n",
        "    \"model\": rf_model,\n",
        "    \"cat_names\": cat_names,\n",
        "    \"cont_names\": cont_names,\n",
        "    \"categorify_maps\": categorify_maps,\n",
        "    \"normalize\": normalization_info,\n",
        "    \"y_names\": [y_col],\n",
        "    \"procs\": [\"Categorify\", \"Normalize\"]\n",
        "}\n",
        "\n",
        "\n",
        "rf_path = path+\"/random_forest_model.pkl\"\n",
        "print(rf_path)\n",
        "\n",
        "with open(rf_path, \"wb\") as f:\n",
        "    pickle.dump(meta_data, f)\n",
        "\n",
        "print(\"Random Forest 모델이 Fastai 형식으로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "aHr5t1PYYAnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 값 예측해보기\n",
        "\n",
        "* 만들어진 랜덤 포레스트 회귀 모델을 통해 값을 예측해보는 코드입니다.\n",
        "* 모델이 잘 돌아가는지를 테스트 하기 위해 필요합니다."
      ],
      "metadata": {
        "id": "sU741Bcbezck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 입력 인터페이스 생성\n",
        "cat_inputs = {}\n",
        "cont_inputs = {}\n",
        "\n",
        "print(\"### 사용자 입력 인터페이스 생성 중...\")\n",
        "\n",
        "# 범주형 입력 위젯 생성\n",
        "for cat in cat_names:\n",
        "    if cat in df.columns:\n",
        "        options = df[cat].unique()\n",
        "        cat_inputs[cat] = widgets.Dropdown(\n",
        "            options=options,\n",
        "            description=f\"{cat}:\",\n",
        "            style={\"description_width\": \"initial\"}\n",
        "        )\n",
        "        display(cat_inputs[cat])\n",
        "\n",
        "# 연속형 입력 위젯 생성\n",
        "for cont in cont_names:\n",
        "    cont_inputs[cont] = widgets.FloatText(\n",
        "        description=f\"{cont}:\",\n",
        "        style={\"description_width\": \"initial\"}\n",
        "    )\n",
        "    display(cont_inputs[cont])\n",
        "\n",
        "# 예측 버튼 생성\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def predict_callback(_):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        try:\n",
        "            # 입력 데이터 준비\n",
        "            input_data = []\n",
        "\n",
        "            # 범주형 데이터 인코딩\n",
        "            for cat in cat_names:\n",
        "                if cat in cat_inputs:\n",
        "                    category = cat_inputs[cat].value\n",
        "                    encoded_value = categorify_maps[cat].o2i[category]  # 인코딩된 값 가져오기\n",
        "                    input_data.append(encoded_value)\n",
        "\n",
        "            # 연속형 데이터 정규화\n",
        "            for cont in cont_names:\n",
        "                if cont in cont_inputs:\n",
        "                    raw_value = cont_inputs[cont].value\n",
        "                    mean = normalization_info[cont][\"mean\"]\n",
        "                    std = normalization_info[cont][\"std\"]\n",
        "                    normalized_value = (raw_value - mean) / std  # 정규화 수행\n",
        "                    input_data.append(normalized_value)\n",
        "\n",
        "            # 예측 수행\n",
        "\n",
        "            columns = cat_names + cont_names  # 열 이름 설정\n",
        "            input_df = pd.DataFrame([input_data], columns=columns)  # DataFrame으로 변환\n",
        "            prediction = rf_model.predict(input_df)[0]\n",
        "            print(f\"예측값: {prediction}\")\n",
        "        except Exception as e:\n",
        "            print(f\"에러 발생: {e}\")\n",
        "\n",
        "predict_button.on_click(predict_callback)\n",
        "display(predict_button, output)\n"
      ],
      "metadata": {
        "id": "qflHo3vnTBXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Xgboost 모델 만들고 값 예측(회귀)해보기\n",
        "\n",
        "* Xgboost 모델 모델은 여러 모델을 조합해 사용하는 앙상블 모델로\n",
        "* 여러 트리 알고리즘을 조합해 사용하는 모델입니다.\n",
        "* 파이썬  XGBRegressor 라이브러리를 활용해 모델을 만들고\n",
        "* 이후 만든 모델을 통해 값을 예측해보겠습니다!"
      ],
      "metadata": {
        "id": "XgkbR9yVe8Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from fastai.tabular.all import *\n",
        "import pickle\n",
        "from sklearn.metrics import r2_score\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "\n",
        "# XGBoost 모델 생성\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=6, random_state=42)\n",
        "xgb_model.fit(train_x, train_y.values.ravel())  # 학습\n",
        "\n",
        "# 검증 데이터 평가\n",
        "preds = xgb_model.predict(valid_x)\n",
        "rmse = np.sqrt(mean_squared_error(valid_y, preds))\n",
        "r2 = r2_score(valid_y, preds)\n",
        "\n",
        "print(f\"XGBoost RMSE: {rmse}\")\n",
        "print(f\"XGBoost R2: {r2}\")\n",
        "\n",
        "# Normalize 및 Categorify 정보 추출\n",
        "normalize_procs = [proc for proc in dls.train.procs if isinstance(proc, Normalize)][0]\n",
        "means = {name: normalize_procs.means[name] for name in cont_names}\n",
        "stds = {name: normalize_procs.stds[name] for name in cont_names}\n",
        "\n",
        "# 정규화 여부 포함\n",
        "def get_normalization_info(name):\n",
        "    return {\n",
        "        \"is_normalized\": name in means,\n",
        "        \"mean\": means.get(name, None),\n",
        "        \"std\": stds.get(name, None)\n",
        "    }\n",
        "\n",
        "normalization_info = {name: get_normalization_info(name) for name in cont_names}\n",
        "\n",
        "# 범주형 변수 매핑 정보 추출\n",
        "categorify_maps = {\n",
        "    cat: dls.classes[cat] for cat in cat_names if cat in dls.classes\n",
        "}\n",
        "\n",
        "# XGBoost 모델 저장\n",
        "meta_data = {\n",
        "    \"model\": xgb_model,\n",
        "    \"cat_names\": cat_names,\n",
        "    \"cont_names\": cont_names,\n",
        "    \"categorify_maps\": categorify_maps,\n",
        "    \"normalize\": normalization_info,\n",
        "    \"y_names\": [y_col],\n",
        "    \"procs\": [\"Categorify\", \"Normalize\"]\n",
        "}\n",
        "\n",
        "xgb_path = path+\"/xgb_model.pkl\"\n",
        "print(rf_path)\n",
        "\n",
        "with open(xgb_path, \"wb\") as f:\n",
        "    pickle.dump(meta_data, f)\n",
        "\n",
        "print(\"XGBoost 모델이 Fastai 형식으로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "yWOivcqVYUtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 값 예측해보기\n",
        "\n",
        "* 만들어진 XGBoost 회귀 모델을 통해 값을 예측해보는 코드입니다.\n",
        "* 모델이 잘 돌아가는지를 테스트 하기 위해 필요합니다."
      ],
      "metadata": {
        "id": "zdGh1pS2fUz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용자 입력 인터페이스 생성\n",
        "cat_inputs = {}\n",
        "cont_inputs = {}\n",
        "\n",
        "print(\"### 사용자 입력 인터페이스 생성 중...\")\n",
        "\n",
        "# 범주형 입력 위젯 생성\n",
        "for cat in cat_names:\n",
        "    if cat in df.columns:\n",
        "        options = df[cat].unique()\n",
        "        cat_inputs[cat] = widgets.Dropdown(\n",
        "            options=options,\n",
        "            description=f\"{cat}:\",\n",
        "            style={\"description_width\": \"initial\"}\n",
        "        )\n",
        "        display(cat_inputs[cat])\n",
        "\n",
        "# 연속형 입력 위젯 생성\n",
        "for cont in cont_names:\n",
        "    cont_inputs[cont] = widgets.FloatText(\n",
        "        description=f\"{cont}:\",\n",
        "        style={\"description_width\": \"initial\"}\n",
        "    )\n",
        "    display(cont_inputs[cont])\n",
        "\n",
        "# 예측 버튼 생성\n",
        "predict_button = widgets.Button(description=\"Predict\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def predict_callback(_):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        try:\n",
        "            # 입력 데이터 준비\n",
        "            input_data = []\n",
        "\n",
        "            # 범주형 데이터 인코딩\n",
        "            for cat in cat_names:\n",
        "                if cat in cat_inputs:\n",
        "                    category = cat_inputs[cat].value\n",
        "                    encoded_value = categorify_maps[cat].o2i[category]  # 인코딩된 값 가져오기\n",
        "                    input_data.append(encoded_value)\n",
        "\n",
        "            # 연속형 데이터 정규화\n",
        "            for cont in cont_names:\n",
        "                if cont in cont_inputs:\n",
        "                    raw_value = cont_inputs[cont].value\n",
        "                    mean = normalization_info[cont][\"mean\"]\n",
        "                    std = normalization_info[cont][\"std\"]\n",
        "                    normalized_value = (raw_value - mean) / std  # 정규화 수행\n",
        "                    input_data.append(normalized_value)\n",
        "\n",
        "            # 예측 수행\n",
        "            columns = cat_names + cont_names\n",
        "            input_df = pd.DataFrame([input_data], columns=columns)  # DataFrame 변환\n",
        "            prediction = xgb_model.predict(input_df)[0]\n",
        "            print(f\"예측값: {prediction}\")\n",
        "        except Exception as e:\n",
        "            print(f\"에러 발생: {e}\")\n",
        "\n",
        "predict_button.on_click(predict_callback)\n",
        "display(predict_button, output)\n"
      ],
      "metadata": {
        "id": "3b6oswrMWVAd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}